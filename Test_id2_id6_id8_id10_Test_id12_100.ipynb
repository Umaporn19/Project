{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA1b6P520GoLTSxvBFOV9a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umaporn19/Project/blob/main/Test_id2_id6_id8_id10_Test_id12_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6kyyKeSyyjH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "AqPWxzpWy4p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "DqnsEfRty6tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/data/id_all.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "40u3sANZy8Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Model/Train_id2_id6_id8_id10_Test_id12_100.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "F1gHzWyDzAOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/Model/Train_id2_id6_id8_id10_Test_id12_100.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "r3uzeV_VzK5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/id\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "test_dir = os.path.join(DATA_PATH, 'test')\n",
        "print(test_dir)"
      ],
      "metadata": {
        "id": "oFQ6FmzJzQpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40,# หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, # Randomly zoom image\n",
        "      horizontal_flip=True, \n",
        "      #โดย Default เมื่อมีการเลื่อนภาพ บิดภาพ หมุนภาพ จะเกิดพื้นที่ว่างที่มุม \n",
        "      #ซึ่งจะมีการเติมภาพให้เต็มโดยใช้เทคนิคแบบ Nearest neighbor ซึ่งเป็นการดึงสีบริเวณใหล้าเคียงมาระบายให้เต็ม แต่เราก็ยังสามารถกำหนดวิธีการ Fill ภาพด้วยเทคนิคอื่นได้จาก Parameter fill_mode\n",
        "      fill_mode='nearest')\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "     \n",
        "\n",
        "#label\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "2RZ4CHwS0FE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = df[df['Unnamed: 0'].between(190080,243527)]\n",
        "test"
      ],
      "metadata": {
        "id": "4agyk5VI0JFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act = test['Part'].tolist()\n",
        "path = test['Path_Name'].tolist()"
      ],
      "metadata": {
        "id": "_-R4ROxc0N9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(img_path): #สร้างฟังก์ชัน \n",
        "    # Read the image and resize it\n",
        "    img = image.load_img(img_path, target_size=(height, width)) #รูปทุกรูปมีขนาดไม่เท่ากันจึงตั้งไว้ว่าเวลาจะให้ model ดึงรูปมาทำนายให้ดึงรูปเข้ามาตามขนาดที่ตั้งไว้ตาม พารามิตเตอร์\n",
        "    # Convert it to a Numpy array with target shape.\n",
        "    x = image.img_to_array(img) # model ไม่สามารถทำนายรูปภาพโดยตรงได้ จึงเเปลงรูปภาพให้เป็น array เเล้วให้โมเดลทำนาย\n",
        "    # Reshape\n",
        "    x = x.reshape((1,) + x.shape) # เพิ่ม ไดเมนชั่นของโมเดล ให้เป็น 4 ได้ เมนชั่น โดยที่ 1, คือบอกให้โมเดลนำเข้าทีละ 1 รูปเเล้วค่อยทำนาย เเละ + ไดเมนชั่น คือ 150 ,150 ,3(สีของ RGB)\n",
        "    x /= 255.\n",
        "    result = model.predict([x])\n",
        "    return result[0]"
      ],
      "metadata": {
        "id": "eK7Me23U0izO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict\n",
        "pred_list = list()\n",
        "prob_list = list()\n",
        "img_path= path\n",
        "for i in range(0,len(img_path)):\n",
        "    predict = predict_image(img_path[i])\n",
        "    result = np.argmax(predict)\n",
        "    pred_list.append(labels[result])\n",
        "    prob_list.append(predict[result])"
      ],
      "metadata": {
        "id": "PITyyYrO0mOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.array(pred_list)\n",
        "act = np.array(act)"
      ],
      "metadata": {
        "id": "q2yBcCsd1HH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# act = data_train['class'].array\n",
        "# pred = data_train['category_ov'].array\n",
        "\n",
        "cmat = confusion_matrix(act, pred)\n",
        "print('classifier accuracy = {}%'.format((100.*np.trace(cmat))/(np.sum(cmat))))\n",
        "\n",
        "#Marking the Confusion Matrix\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(act, pred))#performance"
      ],
      "metadata": {
        "id": "vdtPKIpQ1IeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create CF \n",
        "data = {'Actual': act,'Predicted' : pred,}\n",
        "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
        "conf_mat = pd.crosstab(df['Actual'],df['Predicted'],rownames=['Actual'],colnames=['Predicted'])\n",
        "\n",
        "#Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "cm = confusion_matrix(act, pred)\n",
        "\n",
        "#plot Confusion matrix\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "ax = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
        "ax.set_title('Confusion matrix',fontsize=20)\n",
        "ax.set_ylabel('True label',fontsize=18)\n",
        "ax.set_xlabel('Predicted label',fontsize=18)"
      ],
      "metadata": {
        "id": "x1_rjAy-1Lgd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}